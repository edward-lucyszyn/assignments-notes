\section{Exercise IX: Probabilistic Classifiers: LDA and QDA}

(a) $\forall k \in \llbracket 1, K \rrbracket,$
\[
    f_k(\mathbf{x}) = \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}} \exp(-\frac{1}{2}(\mathbf{x} - \mu_k)^\intercal \Sigma^{-1} (\mathbf{x} - \mu_k)).
\]
Since $t \mapsto \log(t)$ is an increasing function:
\begin{align*}
    \hat{C}(\mathbf{x}) &= \argmax_k f_k(\mathbf{x})\pi_k \\
    &= \argmax_k \log f_k(\mathbf{x})\pi_k \\
    &= \argmax_k \big[- \frac{1}{2} \mathbf{x}^\intercal \Sigma^{-1} \mathbf{x} + \frac{1}{2}\mathbf{x}^\intercal\Sigma^{-1}\mu_k + \frac{1}{2}\mu_k^\intercal\Sigma^{-1}\mathbf{x} - \frac{1}{2}\mu_k^\intercal\Sigma^{-1}\mu_k + \log(\pi_k) + \underbrace{\text{Cst}}_{\substack{\text{does not depend on $k$}}} \big] \\
    &= \argmax_k \big[ \mathbf{x}^\intercal\Sigma^{-1}\mu_k + \mu_k^\intercal\Sigma^{-1}\mathbf{x} - \mu_k^\intercal\Sigma^{-1}\mu_k + 2\log(\pi_k)\big].
\end{align*}
Using the fact that $\mu_k^\intercal\Sigma^{-1}\mathbf{x}$ is a scalar and $\Sigma$ is symmetric (because it is a covariance matrix):
\[
    \mathbf{x}^\intercal\Sigma^{-1}\mu_k = \mu_k^\intercal(\Sigma^{-1})^\intercal \mathbf{x} = \mu_k^\intercal\Sigma^{-1}\mathbf{x}.
\]
Thus,
\[
    \boxed{
    \hat{C}(\mathbf{x}) =\argmax_k \big[ 2\mu_k^\intercal\Sigma^{-1}\mathbf{x} - \mu_k^\intercal\Sigma^{-1}\mu_k + 2\log(\pi_k)\big].
    }
\]
(b) In the case $K=2$, the boundary equation is when $f_1(\mathbf{x}) = f_2(\mathbf{x})$, which gives:
\begin{align*}
   f_1(\mathbf{x}) = f_2(\mathbf{x}) &\iff  2\mu_1^\intercal\Sigma^{-1}\mathbf{x} - \mu_1^\intercal\Sigma^{-1}\mu_1 + 2\log(\pi_1) = 2\mu_2^\intercal\Sigma^{-1}\mathbf{x} - \mu_2^\intercal\Sigma^{-1}\mu_2 + 2\log(\pi_2)\\
   &\iff \boxed{(\mu_1^\intercal - \mu_2^\intercal)\Sigma^{-1}\mathbf{x} = \frac{1}{2}(\mu_1^\intercal\Sigma^{-1}\mu_1 - \mu_2^\intercal\Sigma^{-1}\mu_2) + \log(\frac{\pi_2}{\pi_1}).}
\end{align*}

(c) The MAP rule becomes:
\begin{align*}
    \hat{C}(\mathbf{x}) &= \argmax_k f_k(\mathbf{x})\pi_k \\
    &= \argmax_k \log f_k(\mathbf{x})\pi_k \\
    &= \argmax_k \big[- \frac{1}{2} \mathbf{x}^\intercal \Sigma_k^{-1} \mathbf{x} + \frac{1}{2}\mathbf{x}^\intercal\Sigma_k^{-1}\mu_k + \frac{1}{2}\mu_k^\intercal\Sigma_k^{-1}\mathbf{x} - \frac{1}{2}\mu_k^\intercal\Sigma_k^{-1}\mu_k - \log(\pi_k) - \frac{1}{2}\log|\Sigma_k| \big] \\
    &= \boxed{\argmax_k \big[- \frac{1}{2} \mathbf{x}^\intercal \Sigma_k^{-1} \mathbf{x} + \mu_k^\intercal\Sigma_k^{-1}\mathbf{x} - \frac{1}{2}\mu_k^\intercal\Sigma_k^{-1}\mu_k - \log(\pi_k) - \frac{1}{2}\log|\Sigma_k| \big].}
\end{align*}

(d) QDA stands for "Quadratic Discriminant Analysis." The term "Quadratic" refers to the presence of the term 
\[
- \frac{1}{2} \mathbf{x}^\intercal \Sigma_k^{-1} \mathbf{x}
\]
in the MAP rule. This term is canceled out when $\forall k, \Sigma_k = \Sigma$, but in the case of non-equal covariance assumption, it cannot be eliminated. Therefore, for example, in the scenario of non-equal covariance with $K=2$, the decision boundary equation becomes a quadratic equation, not a linear equation, as seen in question (b).

